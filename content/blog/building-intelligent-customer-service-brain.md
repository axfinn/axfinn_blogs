---
title: "构建智能客服大脑：一个链式处理AI Agent的实践与思考"
date: 2025-07-16
categories: ["技术", "AI", "智能客服", "自动化"]
tags: ["AI Agent", "LLM", "任务编排", "全链路分析", "智能运维"]
---

## 挑战：复杂客户投诉处理的痛点

在互联网服务的日常运营中，客户投诉是不可避免的一环。然而，许多投诉并非简单问题，尤其当它们涉及复杂的系统交互时，例如用户反馈“直播卡顿，需要查看日志并进行全链路分析”。这类问题往往需要：

1.  **多源信息收集**：从日志系统、监控平台、用户行为数据等多个渠道获取信息。
2.  **跨系统关联分析**：根据一个关键标识（如 `trace_id`），关联不同服务间的调用链路。
3.  **动态决策与任务分解**：根据初步分析结果，动态决定下一步需要执行的任务（例如，发现新的关联服务后，需要生成新的查询任务）。
4.  **人工经验依赖**：整个过程高度依赖运维或客服人员的经验，效率低下且容易出错。

为了解决这些痛点，我们设计并实现了一个**链式处理AI Agent**，旨在将这一复杂、多步骤的客户投诉处理流程自动化、智能化。

## 核心思路：打造一个“会思考、能行动”的智能Agent

我们的 AI Agent 并非简单的脚本集合，而是一个具备“思考”、“决策”和“行动”能力的智能实体。其核心设计理念在于模拟人类专家解决问题的过程，并将其自动化：

### 1. 问题理解与意图识别：精准把握用户诉求

**思路：** 自动化处理的第一步是准确理解用户的问题。Agent 需要像经验丰富的客服一样，从用户的自然语言描述中提取关键信息，并识别问题的类型和紧急程度。
**实现：**
*   **LLM驱动的问题优化**：Agent 首先通过一个大型语言模型（LLM）节点（`llmAgentflow_5`，标签为“用户问题理解优化”），对用户输入的原始问题进行深度分析。它被赋予“专业的客诉分析助手”角色，通过系统提示词明确任务：识别问题类型、提取关键信息、优化问题描述、评估紧急程度。
*   **结构化信息提取**：LLM 节点被配置为输出结构化的 JSON 数据，包含 `optimized_question`（优化后的问题描述）、`problem_type`（问题类型）、`uid`（用户ID）和 `room_id`（直播间ID）。这些信息会更新到 Agent 的全局状态变量中，为后续步骤提供清晰的输入。

### 2. 任务规划与动态发现：从问题到可执行步骤

**思路：** 理解问题后，Agent 需要将复杂问题分解为一系列可执行的、原子化的任务。更重要的是，它要能根据任务执行的中间结果，动态地发现并生成新的关联任务，实现真正的“全链路”分析。
**实现：**
*   **初始任务分解**：通过一个 Agent 节点（`agentAgentflow_0`，标签为“拆解用户问题生成TODO任务”），Agent 扮演“任务规划专家”的角色。它接收优化后的问题信息，并利用内置的知识库（`aiVectorRetriever`，例如“开播相关问题知识库”、“互动相关问题知识库”）来查找解决方案，最终生成一个结构化的 `todoList`。
*   **任务调度**：另一个 LLM 节点（`llmAgentflow_7`，标签为“获取一个任务”）充当“智能任务调度器”，负责从 `todoList` 中选择下一个要执行的任务，并将其详细信息（包括工具名称和参数）更新到 `currentTask` 和 `currentTaskParams` 状态变量中。
*   **动态任务发现**：在任务执行过程中，如果发现新的关联信息（例如，通过日志查询工具得到 `trace_id`），Agent 会通过专门的逻辑（在 JSON 配置中体现为对 `discoveredTraceIds` 和 `discoveredServices` 状态变量的更新）来智能地生成新的任务并添加到待执行列表中，从而实现全链路分析的自动化。

### 3. 任务执行与结果审查：确保每一步的质量

**思路：** Agent 不仅要能执行任务，还要能像人类专家一样，对执行结果进行评估和审查，确保信息的准确性和完整性，并为后续决策提供可靠依据。
**实现：**
*   **工具调用与结果处理**：一个核心的 Agent 节点（`agentAgentflow_5`，标签为“任务执行”）扮演“专业的任务执行器”。它严格按照 `currentTask` 中指定的 `tool_id` 和 `params` 调用相应的工具（例如 `biliTool`，这表明它集成了B站内部的特定工具），并处理工具返回的结果。
*   **结果审查与精炼**：任务执行后，一个 LLM 节点（`llmAgentflow_8`，标签为“结果review”）会介入，对任务执行结果进行质量评估。它会提取关键发现、识别潜在问题，并生成精炼的摘要。这确保了“Garbage in, garbage out”的问题不会发生。审查结果会更新到 `currentTaskReviewedResult` 状态变量。
*   **状态更新与汇总**：另一个 LLM 节点（`llmAgentflow_9`，标签为“已完成的任务处理”）负责聚合所有任务的原始结果和审查结果，更新 `taskResults` 数组，并计算 `completedTasks` 和 `remaining_count`，实时反映整体进度。

### 4. 健壮的流程控制与状态管理：保障Agent稳定运行

**思路：** 自动化流程的复杂性要求 Agent 具备强大的自我管理和控制能力，以防止无限循环、资源耗尽等问题，并确保流程能够稳定、可控地结束。
**实现：**
*   **统一状态中心**：`startAgentflow_0` 节点初始化了所有关键状态变量（`todoList`, `currentTask`, `taskResults`, `completedTasks`, `failedTasks`, `discoveredTraceIds`, `discoveredServices` 等）。这些变量在整个流程中被不同节点共享和更新，确保了数据流的连贯性和一致性。
*   **循环与终止条件**：LLM 节点（`llmAgentflow_10`，标签为“是否继续”）充当决策者，根据 `remaining_count` 和预设的安全限制（如最大循环次数）判断是否继续执行下一个任务。如果需要继续，流程会通过“继续处理”节点（`llmAgentflow_11`）返回到任务调度环节，形成一个闭环。当所有任务完成或达到安全限制时，流程会进入“完成汇总”节点（`llmAgentflow_12`）并终止。

## Agent工作流程概览

以下流程图展示了智能体如何通过一系列精心设计的节点，将复杂问题逐步分解、执行、审查并最终汇总：

{{< mermaid >}}
graph TD
    A[01_Start] --> B[02_用户问题理解优化]
    B --> C[03_拆解用户问题生成TODO任务]
    C --> D[04_任务列表处理]
    D --> E[05_获取一个任务]
    E --> F{有可用任务?}
    F -- Yes --> G[06_任务执行]
    G --> H[07_结果review]
    H --> I[07.5_动态任务发现]
    I --> J[07.6_任务列表更新]
    J --> K[08_已完成的任务处理]
    K --> L[09_是否继续]
    L -- Yes --> E
    L -- No --> M[11_完成汇总]
    F -- No --> M
{{< /mermaid >}}

## 总结与展望

这个链式处理 AI Agent 的实践，为自动化复杂客户投诉处理提供了一个强大的解决方案。它通过模拟人类专家的思考和行动模式，将多源信息收集、跨系统关联分析和动态决策等环节有机结合，显著提升了处理效率和准确性。

这套设计理念和工程实践，不仅适用于客户投诉场景，也为其他需要复杂任务编排和动态决策的自动化流程提供了宝贵的参考。未来，我们将继续优化 Agent 的能力，使其更加智能、高效，为用户提供更优质的服务体验。
